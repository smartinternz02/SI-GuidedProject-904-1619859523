{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D#add convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D#add maxpooling layer\n",
    "from tensorflow.keras.layers import Flatten#add flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1677 images belonging to 5 classes.\n",
      "Found 750 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(\"/Users/sunny/Downloads/Telegram Desktop/flowers/trainset\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")\n",
    "x_test=test_datagen.flow_from_directory(\"/Users/sunny/Downloads/Telegram Desktop/flowers/testset\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512,activation=\"relu\",kernel_initializer=\"random_uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=5,activation=\"softmax\",kernel_initializer=\"random_uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"sgd\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunny/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "47/47 [==============================] - 34s 711ms/step - loss: 1.5740 - accuracy: 0.2919 - val_loss: 1.4949 - val_accuracy: 0.3766\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 13s 285ms/step - loss: 1.4223 - accuracy: 0.3874 - val_loss: 1.3701 - val_accuracy: 0.4203\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 13s 275ms/step - loss: 1.3458 - accuracy: 0.4125 - val_loss: 1.2892 - val_accuracy: 0.4547\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 13s 272ms/step - loss: 1.2598 - accuracy: 0.4475 - val_loss: 1.2890 - val_accuracy: 0.4703\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 1.2546 - accuracy: 0.4696 - val_loss: 1.2840 - val_accuracy: 0.4484\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 1.1942 - accuracy: 0.4964 - val_loss: 1.3378 - val_accuracy: 0.4000\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 14s 289ms/step - loss: 1.1577 - accuracy: 0.5182 - val_loss: 1.2731 - val_accuracy: 0.4625\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 21s 442ms/step - loss: 1.1425 - accuracy: 0.5117 - val_loss: 1.2266 - val_accuracy: 0.4734\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 97s 2s/step - loss: 1.1183 - accuracy: 0.5454 - val_loss: 1.2823 - val_accuracy: 0.4703\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 34s 730ms/step - loss: 1.0938 - accuracy: 0.5521 - val_loss: 1.2127 - val_accuracy: 0.4812\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 35s 747ms/step - loss: 1.0850 - accuracy: 0.5564 - val_loss: 1.1741 - val_accuracy: 0.5016\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 41s 875ms/step - loss: 1.0584 - accuracy: 0.5811 - val_loss: 1.2335 - val_accuracy: 0.4891\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 49s 1s/step - loss: 1.0525 - accuracy: 0.5812 - val_loss: 1.1932 - val_accuracy: 0.5078\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 46s 981ms/step - loss: 1.0434 - accuracy: 0.5976 - val_loss: 1.2184 - val_accuracy: 0.5094\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 40s 863ms/step - loss: 0.9928 - accuracy: 0.6112 - val_loss: 1.1837 - val_accuracy: 0.5078\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 39s 823ms/step - loss: 1.0108 - accuracy: 0.6031 - val_loss: 1.1561 - val_accuracy: 0.5266\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 38s 811ms/step - loss: 0.9822 - accuracy: 0.6225 - val_loss: 1.1927 - val_accuracy: 0.5156\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 30s 643ms/step - loss: 1.0230 - accuracy: 0.5997 - val_loss: 1.1876 - val_accuracy: 0.5031\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 36s 756ms/step - loss: 0.9734 - accuracy: 0.6302 - val_loss: 1.1773 - val_accuracy: 0.5297\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 37s 787ms/step - loss: 0.9584 - accuracy: 0.6305 - val_loss: 1.1623 - val_accuracy: 0.5266\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 20s 433ms/step - loss: 0.9509 - accuracy: 0.6330 - val_loss: 1.1781 - val_accuracy: 0.5391\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 23s 500ms/step - loss: 0.9646 - accuracy: 0.6245 - val_loss: 1.2203 - val_accuracy: 0.5188\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 27s 567ms/step - loss: 0.9578 - accuracy: 0.6419 - val_loss: 1.2234 - val_accuracy: 0.5141\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 27s 583ms/step - loss: 0.9760 - accuracy: 0.6295 - val_loss: 1.1494 - val_accuracy: 0.5672\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 46s 976ms/step - loss: 0.8905 - accuracy: 0.6459 - val_loss: 1.1652 - val_accuracy: 0.5344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9532240cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=47,epochs=25,validation_data=x_test,validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flowers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[\"daisy\",\"dandelion\",\"rose\",\"sunflower\",\"tulip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"flowers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load img\n",
    "img=image.load_img(\"/Users/sunny/Desktop/Geethanjaliexternship1/rose.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunny/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rose'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the flower is rose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
